{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('week14')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# create file handler which logs even debug messages\n",
    "fh = logging.FileHandler('../logs/week14.log')\n",
    "fh.setLevel(logging.DEBUG)\n",
    "# create console handler with a higher log level\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "# create formatter and add it to the handlers\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "fh.setFormatter(formatter)\n",
    "# add the handlers to logger\n",
    "logger.addHandler(ch)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "# 'application' code\n",
    "# logger.debug('debug message')\n",
    "# logger.info('info message')\n",
    "# logger.warning('warn message')\n",
    "# logger.error('error message')\n",
    "# logger.critical('critical message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20201201'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = dt.datetime.today().strftime('%Y%m%d')\n",
    "now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading raw data from sklearn\n",
    "df_digits = load_digits()\n",
    "\n",
    "# creating feature and target data\n",
    "X = df_digits['data']\n",
    "y = df_digits['target']\n",
    "\n",
    "\n",
    "assert X.shape == (1797, 64)\n",
    "assert y.shape[0] == 1797\n",
    "\n",
    "assert X.shape[0] == y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-01 20:59:26,020 - week14 - INFO - Train test set created...\n"
     ]
    }
   ],
   "source": [
    "# Create train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "logger.info('Train test set created...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: do more EDAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_test).to_csv('../data/X_test.csv', sep=',', index=False)\n",
    "pd.DataFrame(X_test).head(1).to_csv('../data/X_test_sample.txt', sep=',', header=False, index=False)\n",
    "\n",
    "\n",
    "pd.DataFrame(y_test).to_csv('../data/y_test.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a classifier - here I am using a Random Forest model\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "pipe = Pipeline([('classifier', clf)])\n",
    "\n",
    "# Parameters of the pipeline\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [2, 4, 6]\n",
    "}\n",
    "logger.info('grid search started')\n",
    "search = GridSearchCV(pipe,  param_grid, n_jobs=-1, cv=5, return_train_score=True)\n",
    "logger.info('grid search ended')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../model'\n",
    "model_name = 'clf_rf_{}'.format(now)\n",
    "\n",
    "\n",
    "# joblib.dump(search.best_estimator_, os.path.join(model_dir, model_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
